{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import CLoader as Loader\n",
    "\n",
    "from munch import munchify\n",
    "\n",
    "from vicreg import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Munch({'root_dir': '/home/minh/PycharmProjects/prostate_cancer_classification_v1', 'exp_dir': 'experiments/vicreg_patch', 'log_freq_time': 60, 'arch': 'resnet50', 'mlp': '8192-8192-8192', 'epochs': 1, 'batch_size': 128, 'base_lr': 0.2, 'wd': '1e-6', 'sim_coef': 25.0, 'std_coef': 25.0, 'cov_coef': 1.0, 'num_workers': 10, 'device': 'cuda', 'world_size': 1, 'local_rank': -1, 'dist_url': 'env://'})\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/minh/PycharmProjects/prostate_cancer_classification_v1'\n",
    "with open(f'{root_dir}/yamls/vicreg_patch.yml') as f:\n",
    "    args = yaml.load(f, Loader)\n",
    "args = munchify(args)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils_3d.dataset import PatchUnlabeledDataset\n",
    "from augmentations import TwoCropsTransform\n",
    "\n",
    "data_root = '/media/minh/My Passport/workspace/Preparation/DataPreparation/dummy/snapshots_in_use_Amoon_2''/patch_32x32_whole_prostate/'\n",
    "dataset = PatchUnlabeledDataset(data_root, TwoCropsTransform(), pid_range=(0, 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Munch({'root_dir': '/home/minh/PycharmProjects/prostate_cancer_classification_v1', 'exp_dir': 'experiments/vicreg_patch', 'log_freq_time': 60, 'arch': 'resnet50', 'mlp': '8192-8192-8192', 'epochs': 1, 'batch_size': 128, 'base_lr': 0.2, 'wd': '1e-6', 'sim_coef': 25.0, 'std_coef': 25.0, 'cov_coef': 1.0, 'num_workers': 10, 'device': 'cuda', 'world_size': 1, 'local_rank': -1, 'dist_url': 'env://'})\n",
      "/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel_launcher.py -f /home/minh/.local/share/jupyter/runtime/kernel-dd7b7588-497e-49f6-9b65-66f2d053c469.json\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "# init_distributed_mode(args)\n",
    "print(args)\n",
    "gpu = torch.device(args.device)\n",
    "args.exp_dir = '/'.join([args.root_dir, args.exp_dir])\n",
    "os.makedirs(args.exp_dir, exist_ok=True)\n",
    "stats_file = open('/'.join([args.exp_dir, \"stats.txt\"]), \"a\", buffering=1)\n",
    "print(\" \".join(sys.argv))\n",
    "print(\" \".join(sys.argv), file=stats_file)\n",
    "\n",
    "per_device_batch_size = args.batch_size // args.world_size\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=per_device_batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=False,\n",
    ")\n",
    "model = VICReg(args).cuda(gpu)\n",
    "optimizer = LARS(\n",
    "    model.parameters(),\n",
    "    lr=0,\n",
    "    weight_decay=args.wd,\n",
    "    weight_decay_filter=exclude_bias_and_norm,\n",
    "    lars_adaptation_filter=exclude_bias_and_norm,\n",
    ")\n",
    "if os.path.exists('/'.join([args.exp_dir, \"model.pth\"])):\n",
    "    ckpt = torch.load('/'.join([args.exp_dir, \"model.pth\"]), map_location=\"cpu\")\n",
    "    start_epoch = ckpt[\"epoch\"]\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "else:\n",
    "    start_epoch = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in VarBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/minh/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1175976/3641279922.py\", line 11, in <cell line: 3>\n",
      "    loss = model.forward(x, y)\n",
      "  File \"/home/minh/PycharmProjects/prostate_cancer_classification_v1/training_strategy/self_supervised_learning/vicreg/vicreg.py\", line 204, in forward\n",
      "    std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
      " (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/torch/csrc/autograd/python_anomaly_mode.cpp:102.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'VarBackward0' returned nan values in its 0th output.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast():\n\u001B[1;32m     11\u001B[0m     loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(x, y)\n\u001B[0;32m---> 12\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[1;32m     14\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Function 'VarBackward0' returned nan values in its 0th output."
     ]
    }
   ],
   "source": [
    "start_time = last_logging = time.time()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(start_epoch, args.epochs):\n",
    "    for step, (x, y) in enumerate(loader, start=epoch * len(loader)):\n",
    "        x = x.cuda(gpu, non_blocking=True)\n",
    "        y = y.cuda(gpu, non_blocking=True)\n",
    "        lr = adjust_learning_rate(args, optimizer, loader, step)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = model.forward(x, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        break\n",
    "\n",
    "        current_time = time.time()\n",
    "        if current_time - last_logging > args.log_freq_time:\n",
    "            stats = dict(\n",
    "                epoch=epoch,\n",
    "                step=step,\n",
    "                loss=loss.item(),\n",
    "                time=int(current_time - start_time),\n",
    "                lr=lr,\n",
    "            )\n",
    "            print(json.dumps(stats))\n",
    "            print(json.dumps(stats), file=stats_file)\n",
    "            last_logging = current_time\n",
    "    state = dict(\n",
    "        epoch=epoch + 1,\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "    )\n",
    "    torch.save(state, args.exp_dir / \"model.pth\")\n",
    "\n",
    "torch.save(model.module.backbone.state_dict(), args.exp_dir / \"resnet50.pth\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.backbone"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
